{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IBM_ADMIN\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32, (3,3), input_shape=(64,64,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n",
    "                   metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5161 images belonging to 2 classes.\n",
      "Found 2023 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "rescale=1./255,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True,\n",
    "fill_mode='nearest')\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('CNN_Data/training_set',\n",
    "target_size = (64, 64),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('CNN_Data/test_set',\n",
    "target_size = (64, 64),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 2738s 342ms/step - loss: 0.5627 - acc: 0.7007 - val_loss: 0.6431 - val_acc: 0.6622\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 2757s 345ms/step - loss: 0.5249 - acc: 0.7311 - val_loss: 0.5948 - val_acc: 0.6875\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 2581s 323ms/step - loss: 0.5087 - acc: 0.7450 - val_loss: 0.6232 - val_acc: 0.6959\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 2502s 313ms/step - loss: 0.4959 - acc: 0.7536 - val_loss: 0.5911 - val_acc: 0.7143\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 2443s 305ms/step - loss: 0.4857 - acc: 0.7610 - val_loss: 0.6661 - val_acc: 0.6989\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 2476s 309ms/step - loss: 0.4797 - acc: 0.7665 - val_loss: 0.6151 - val_acc: 0.7138\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 2469s 309ms/step - loss: 0.4735 - acc: 0.7703 - val_loss: 0.6725 - val_acc: 0.7043\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 2505s 313ms/step - loss: 0.4681 - acc: 0.7732 - val_loss: 0.6041 - val_acc: 0.7321\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 2651s 331ms/step - loss: 0.4628 - acc: 0.7771 - val_loss: 0.7818 - val_acc: 0.6597\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 2433s 304ms/step - loss: 0.4596 - acc: 0.7809 - val_loss: 0.7270 - val_acc: 0.6727\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 2487s 311ms/step - loss: 0.4559 - acc: 0.7821 - val_loss: 0.6361 - val_acc: 0.7247\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 2393s 299ms/step - loss: 0.4535 - acc: 0.7833 - val_loss: 0.6492 - val_acc: 0.6963\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 2361s 295ms/step - loss: 0.4482 - acc: 0.7862 - val_loss: 0.6492 - val_acc: 0.7233\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 2355s 294ms/step - loss: 0.4486 - acc: 0.7872 - val_loss: 0.5959 - val_acc: 0.7295\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 2330s 291ms/step - loss: 0.4450 - acc: 0.7893 - val_loss: 0.7849 - val_acc: 0.7009\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 2385s 298ms/step - loss: 0.4424 - acc: 0.7910 - val_loss: 0.7647 - val_acc: 0.6898\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 2352s 294ms/step - loss: 0.4393 - acc: 0.7933 - val_loss: 0.6632 - val_acc: 0.7115\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 2299s 287ms/step - loss: 0.4386 - acc: 0.7931 - val_loss: 0.6373 - val_acc: 0.7413\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 2309s 289ms/step - loss: 0.4376 - acc: 0.7934 - val_loss: 0.7087 - val_acc: 0.7153\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 2312s 289ms/step - loss: 0.4340 - acc: 0.7957 - val_loss: 0.7209 - val_acc: 0.7008\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 2311s 289ms/step - loss: 0.4333 - acc: 0.7962 - val_loss: 0.7662 - val_acc: 0.6786\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 2322s 290ms/step - loss: 0.4317 - acc: 0.7976 - val_loss: 0.7342 - val_acc: 0.6999\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 2346s 293ms/step - loss: 0.4313 - acc: 0.7979 - val_loss: 0.9481 - val_acc: 0.6653\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 2408s 301ms/step - loss: 0.4271 - acc: 0.8003 - val_loss: 0.7077 - val_acc: 0.6936\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 2376s 297ms/step - loss: 0.4280 - acc: 0.8003 - val_loss: 0.8365 - val_acc: 0.6653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x141c4240>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "steps_per_epoch = 8000,\n",
    "epochs = 25,\n",
    "validation_data = test_set,\n",
    "validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "prediction = ''\n",
    "print(result)\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
